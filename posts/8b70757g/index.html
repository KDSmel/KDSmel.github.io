<!DOCTYPE html>
<html class="theme-next mist use-motion" lang>
<head><meta name="generator" content="Hexo 3.9.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<script>
    (function(){
        if(''){
            if (prompt('Show me your password') !== ''){
                alert('Blah, wrong.');
                history.back();
            }
        }
    })();
</script>
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
  <link rel="stylesheet" href="/lib/Han/dist/han.min.css?v=3.3">
  <link rel="stylesheet" href="/lib/fancybox/source/jquery.fancybox.css">
<link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="/css/main.css?v=7.1.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.1.2">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.1.2">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.1.2">
  <link rel="mask-icon" href="/images/logo.svg?v=7.1.2" color="#222">
  <meta name="description" content="Introduction In this project, I developed a financial data processing and visualization platform using Apache Kafka, Apache Cassandra, and Bokeh. I used Kafka for realtime stock price and market news">
<meta name="keywords" content="Bokeh,Kafka,Cassandra">
<meta property="og:type" content="article">
<meta property="og:title" content="Realtime Financial Market Data Visualization and Analysis">
<meta property="og:url" content="https://kdsmel.github.io/posts/109fc1d1/index.html">
<meta property="og:site_name" content="Kamel&#39;s Notes">
<meta property="og:description" content="Introduction In this project, I developed a financial data processing and visualization platform using Apache Kafka, Apache Cassandra, and Bokeh. I used Kafka for realtime stock price and market news">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://kdsmel.github.io/posts/109fc1d1/kafka_stock.png">
<meta property="og:image" content="https://kdsmel.github.io/posts/109fc1d1/tab1.gif">
<meta property="og:image" content="https://kdsmel.github.io/posts/109fc1d1/tab2.gif">
<meta property="og:image" content="https://kdsmel.github.io/posts/109fc1d1/tab3.gif">
<meta property="og:image" content="https://kdsmel.github.io/posts/109fc1d1/stream1.png">
<meta property="og:image" content="https://kdsmel.github.io/posts/109fc1d1/fundamental.png">
<meta property="og:image" content="https://kdsmel.github.io/posts/109fc1d1/click.png">
<meta property="og:image" content="https://kdsmel.github.io/posts/109fc1d1/news.png">
<meta property="og:updated_time" content="2019-10-20T01:56:49.312Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Realtime Financial Market Data Visualization and Analysis">
<meta name="twitter:description" content="Introduction In this project, I developed a financial data processing and visualization platform using Apache Kafka, Apache Cassandra, and Bokeh. I used Kafka for realtime stock price and market news">
<meta name="twitter:image" content="https://kdsmel.github.io/posts/109fc1d1/kafka_stock.png">
  <link rel="alternate" href="/atom.xml" title="Kamel's Notes" type="application/atom+xml">
  <link rel="canonical" href="https://kdsmel.github.io/posts/109fc1d1/">
<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>
  <title>Identifying Seismic Waves with Convolutional Neural Networks | Kamel's Notes</title>
  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }
  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }
  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>
<body itemscope itemtype="http://schema.org/WebPage" lang="default">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Kamel's Notes</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">Code changes world!</p>
  </div>
  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>
<nav class="site-nav">
    <ul id="menu" class="menu">
          <li class="menu-item menu-item-home">
    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>
  </li>
          <li class="menu-item menu-item-ml">
    <a href="/categories/Machine-Learning" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>ML</a>
  </li>
          <li class="menu-item menu-item-big-data">
    <a href="/categories/Big-Data" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Big Data</a>
  </li>
             <li class="menu-item menu-item-big-projects menu-item-active">
    <a href="/categories/Project" rel="section"><i class="menu-item-icon fa fa-fw fa-tasks"></i> <br>Projects</a>
  </li>
          <li class="menu-item menu-item-journal">
    <a href="/categories/Journal/" rel="section"><i class="menu-item-icon fa fa-fw fa-coffee"></i> <br>Journal</a>
  </li>
      <li class="menu-item menu-item-about">
    <a href="/resume/" rel="section"><i class="menu-item-icon fa fa-fw fa-address-card-o"></i> <br>About</a>
  </li>      
    </ul>
</nav>
</div>
    </header>
    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
  <div id="posts" class="posts-expand">
  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kdsmel.github.io/posts/109fc1d1/">
    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kamel Chehboun">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>
    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kamel's Notes">
    </span>
      <header class="post-header">
          <h1 class="post-title" itemprop="name headline">Identifying Seismic Waves with Convolutional Neural Networks
          </h1>
        <div class="post-meta">
          <span class="post-time">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
                <span class="post-meta-item-text">Posted on</span>
              <time title="Created: 2019-10-19 20:51:45 / Modified: 20:56:49" itemprop="dateCreated datePublished" datetime="2019-10-19T20:51:45-05:00">2019-10-19</time>
          </span>
            <span class="post-category">
              <span class="post-meta-divider">|</span>
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
                <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Project/" itemprop="url" rel="index"><span itemprop="name">Project</span></a></span>
            </span>
            <div class="post-symbolscount">
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                  <span class="post-meta-item-text">Symbols count in article: </span>
                <span title="Symbols count in article">5.9k</span>
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                <span title="Reading time">5 mins.</span>
            </div>
        </div>
      </header>
    <div class="post-body han-init-context" itemprop="articleBody">
<!DOCTYPE html>
<html lang="en-us">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.5.0">
  <meta name="author" content="Noah Luna">
  <meta name="description" content="In Part I we covered the first steps of our machine learning pipeline: Framing the Problem, Retrieving the Data , Exploring and Understanding your Data, and Processing the Data for training .
In this tutorial we will go sraight into compiling, training, and evaluating a baseline convolutional neural network. We&rsquo;ll end by going over what still needs to be done before we can consider this model ready for deployment.">
  <link rel="alternate" hreflang="en-us" href="https://ngrayluna.github.io/post/p-phase-picker-tutorial/">
  <meta name="theme-color" content="#328cc1">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.css" integrity="sha512-M2wvCLH6DSRazYeZRIm1JnYyh22purTM+FDB5CsyxtQJYeKq83arPe5wgbNmcFXGqiSH2XR8dT/fJISVA1r/zQ==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  <link rel="stylesheet" href="/css/academic.min.62b22f09e99190cb4a0bd1cbb8c2cd5d.css">
  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon-32.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">
  <link rel="canonical" href="https://ngrayluna.github.io/post/p-phase-picker-tutorial/">
  <meta property="twitter:card" content="summary">
  <meta property="og:site_name" content="Gray Luna">
  <meta property="og:url" content="https://ngrayluna.github.io/post/p-phase-picker-tutorial/">
  <meta property="og:title" content="Identifying Seismic Waves with Convolutional Neural Networks [Part II] | Gray Luna">
  <meta property="og:description" content="In Part I we covered the first steps of our machine learning pipeline: Framing the Problem, Retrieving the Data , Exploring and Understanding your Data, and Processing the Data for training .
In this tutorial we will go sraight into compiling, training, and evaluating a baseline convolutional neural network. We&rsquo;ll end by going over what still needs to be done before we can consider this model ready for deployment."><meta property="og:image" content="https://ngrayluna.github.io/img/icon-192.png">
  <meta property="twitter:image" content="https://ngrayluna.github.io/img/icon-192.png"><meta property="og:locale" content="en-us">
      <meta property="article:published_time" content="2019-10-01T01:00:00&#43;00:00">
    <meta property="article:modified_time" content="2019-10-01T11:43:17-07:00">
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://ngrayluna.github.io/post/p-phase-picker-tutorial/"
  },
  "headline": "Identifying Seismic Waves with Convolutional Neural Networks [Part II]",
  "datePublished": "2019-10-01T01:00:00Z",
  "dateModified": "2019-10-01T11:43:17-07:00",
  "author": {
    "@type": "Person",
    "name": "Noah Luna"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Gray Luna",
    "logo": {
      "@type": "ImageObject",
      "url": "https://ngrayluna.github.io/img/icon-512.png"
    }
  },
  "description": "In Part I we covered the first steps of our machine learning pipeline: Framing the Problem, Retrieving the Data , Exploring and Understanding your Data, and Processing the Data for training .\nIn this tutorial we will go sraight into compiling, training, and evaluating a baseline convolutional neural network. We\u0026rsquo;ll end by going over what still needs to be done before we can consider this model ready for deployment."
}
</script>
</head>
<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >
<p>In <a href ="https://ngrayluna.github.io/post/p-phase-picker-tutorial_pi/">Part I</a> we covered the first steps of our machine learning pipeline: <b>Framing the Problem</b>, <b>Retrieving the Data </b>, <b>Exploring and Understanding your Data</b>, and <b>Processing the Data for training </b>.</p>
<p>In this tutorial we will go sraight into <b>compiling</b>, <b>training</b>, and <b>evaluating</b> a baseline convolutional neural network.  We&rsquo;ll end by going over what still needs to be done before we can consider this model ready for deployment.</p>
<hr />
<h2>Table of Contents</h2>
<ul>
<li><a href="#read_data">Read Data In</a></li>
<li><a href="#cnn_baseline">A Convolutional Neural Network Baseline</a></li>
<li><a href="#train_model">Training Model</a></li>
<li><a href="#interpreting_results">Interpreting the Results</a></li>
<li><a href="#visualize_results">Visualizing the Results</a></li>
<li><a href="#whats_next">What&rsquo;s Next</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
<hr />
<p><br>
Let&rsquo;s get started! Open a Jupyter Notebook or your favorite Python IDE and include the following modules and functions:</p>
<pre><code class="language-python">import os
import numpy as np
import pandas as pd
from random import randint
from keras.layers import Input, Dense
from keras.layers import Conv1D, MaxPooling1D, UpSampling1D
from keras.layers.normalization import BatchNormalization
from keras.layers import Dropout, Activation, Flatten
from keras.models import Model
from keras.models import model_from_json
import matplotlib.pyplot as plt
plt.style.use('ggplot')
</code></pre>
<pre><code class="language-python">def form_WAVsaved_npz(data_array):
    tmp_list = []
    for array in data_array:
        tmp_list.append(data_array[array])
    # Convert to Numpy array
    # (# of instances, # of features)
    data_array = np.array(tmp_list)  
    # From (1, 7156, 3, 1800) to (7156, 3, 1800)
    data_array = data_array.reshape(data_array.shape[1], data_array.shape[2], data_array.shape[3])
    return data_array
def format_Psaved_npz(label_array):
    tmp_list = []
    for array in label_array:
        tmp_list.append(label_array[array])
    # Convert to Numpy array
    # (# of instances, # of features)
    data_array = np.array(tmp_list)  
    # (1, #samples, labels)
    labels = data_array.reshape(data_array.shape[1])
    return labels
</code></pre>
<p><br>
<h2><a name='read_data'>Read Data In</a></h2></p>
<p>For this model, we are using the data saved from our pre-processing efforts in the last tutorial. Recall that in the last post we saved our data (time-series waveforms) and their associated labels (arrival times of the first arriving P-Phase seismic wave) into Numpy&rsquo;s compressed file format.</p>
<p>There are two files to read in: time-series waveforms and the arrival times of the first arriving (P-Phase) seismic wave. The latter of which are the labels we are using for our training model. Simply use <span style="font-family:Courier; font-size:1.0em;">np.load()</span> to read both .npz files in.  Once the files are in memory we&rsquo;ll store them in NumPy arrays. I&rsquo;ve written a function to then take this  <span style="font-family:Courier; font-size:1.0em;">numpy.lib.npyio.NpzFile</span> and store it into a NumPy array.</p>
<pre><code class="language-python"># Let's read this in and check it is right.
data_waves = np.load(&quot;./pre_process/waveforms.npz&quot;)
data_labels = np.load(&quot;./pre_process/labels.npz&quot;)   # labels
data_array = form_WAVsaved_npz(data_waves)
p_arrivals = format_Psaved_npz(data_labels)
</code></pre>
<p>To make our lives easier we’ll also assign the number of traces, the number of features, and the number of sample points to variables num_traces, num_feat, and npts, respectively.
<span style="font-family:Courier; font-size:1.0em;">num_traces</span>, <span style="font-family:Courier; font-size:1.0em;">num_feat</span>, and <span style="font-family:Courier; font-size:1.0em;">npts</span>, respectively.</p>
<pre><code class="language-python"># Number of traces
num_traces = data_array.shape[0]   # e.g. (1, 5, 3)
# Index of feature we want.
num_feat   = data_array.shape[2]
# npts
npts = data_array.shape[1]
</code></pre>
<p>At this point, we need to set aside some of our data for training and set aside the remaining data for our validation set. For “smaller” data sets it is common to use 80% of your data set for training and set aside the other 20% for validation. If you have a data set in the millions, then you’ll probably end up using 10% of your data for validation and the rest for training.</p>
<p>To split our data set we will set<br />
<center><span style="font-family:Courier; font-size:1.0em;">TRAIN_TEST_SPLIT = 0.2</span></center></p>
<p>In other words, we&rsquo;re keeping 80% for training and the remaining 20% for validation.</p>
<pre><code class="language-python"># Split data into training and validation 
# The percent of data that will be included in the test set (here 20%)
TRAIN_TEST_SPLIT = 0.2
# TRAIN/VAL split 
nr_val_data = int(num_traces * TRAIN_TEST_SPLIT)
x_train = data_array[nr_val_data:, :] # x composed of two traces
y_train = p_arrivals[nr_val_data :] # y values has the s-arrival time
x_val  = data_array[:nr_val_data, :]
y_val  = p_arrivals[: nr_val_data]
</code></pre>
<hr />
<h2><a name = 'cnn_baseline'>A Convolutional Neural Network Baseline</a></h2>
<p>So far we have read our data into our notebook, formatted it into NumPy arrays, and we just split the data into a training and validation training set. Let’s now define our deep neural network! As stated in the title of this blog and the previous post, we will be using convolutional neural networks (CNN). Among other things, CNN are designed to handle grid-like data such as time-series data and images. Alternatively, we could use a Recurrent Neural Network (RNN) which can also handle data with spatial-temporal dependencies. Let’s stick to CNNs as they are currently one of the most successful models in the field of Computer Vision.</p>
<p>To create our convolutional neural network model we will use <a href="https://keras.io/" target="_blank">Keras</a> which is a high-level neural network API. It is fairly straight forward to use and the community supporting Keras is robust.</p>
<p><br>
<h3>Hyperparameter Choice</h3></p>
<p>We are now ready to define some hyperparameters. Unfortunately, there does not exist a set of rules which will tell you what hyperparameters you should use. The process of fine-tuning your model is empirical and requires a lot of trial and error. However, that doesn’t mean you should start choosing randomly. For a starting point, read up on current best practices, learn what model configurations are working for other groups, and do a little homework on which parameters are appropriate. I&rsquo;ve gone ahead and done this for this tutorial. With that said, we&rsquo;ll be using the following hyperparameters:</p>
<ul>
<li>Mini batches of 256 [memory on computers is stored in 2&rsquo;s, so batches of a power of 2 helps train a little faster]<br /></li>
<li>400 epochs [let&rsquo;s just start with this]<br /></li>
<li>Filters size of 32 and 64<br /></li>
<li>Kernel size of size 6</li>
<li>Pool size of 2<br /></li>
<li>Rectified linear unit (ReLU) activation function for the hidden layers</li>
<li>Linear activation function for the output layer [we want an activation function which can give us values between -1 to 1]</li>
<li>Mean squared error loss function<br /></li>
<li>Adam optimizer [best of RMSprop and gradient decent with momentum]</li>
</ul>
<p>If you have experience using convolutional neural networks, you’ll already know that in addition to specifying the input size, we also need to define the number of channels. Thus, our input will have the form of:</p>
<p><centre><span style="font-family:Courier; font-size:1.0em;">(# training examples, number of samples, # of channels)</span></centre>.</p>
<p>Seismometers record motion in three directions: a vertical(up-down) and two horizontal motions (N-S and E-W). Thus, for each training example, we will give our neural network not just one, but three waveforms. Thus, our input array will have three channels. Below is an illustration of what our CNN looks like:</p>
<p><img src = './img/three_comp_cnn.png'>
<b>Figure:</b> Schematic of the 1D convolutional neural network used to identify the first-arriving phase arrival of an earthquake. Note that each instance is composed of three channels, one for each component measured by the seismometer (Vertical, North-South, East-West).</p>
<p>For the sake of brevity, I’ll omit commentary on how we chose the number of hidden layers and the filter size (sometimes referred to as ‘kernels’) in this blog. I’ll make a separate blog detailing the nitty-gritty details of how convolutional neural networks work.</p>
<p>With this in mind let’s go ahead and make our convolutional neural network.   Below is a summary of our model. Each line describes a hidden layer and it’s associated number of weights and parameters. Our input array, <span style="font-family:Courier; font-size:1.0em;"> x_train</span>, has input dimension of:</p>
<p>which we store in as a variable labeled <span style="font-family:Courier; font-size:1.0em;">input_trace</span>.</p>
<pre><code class="language-python"># Hyperparameters 
batch_size = 256
epochs     = 400
filters    = [32, 64]
kernel_size = 6
pool_size = 2
padding = 'same'
hidden_act_fun = 'relu'
final_act_fun  = 'linear'
optimizer = 'adam'
loss_type = 'mean_squared_error' 
name = 's_phase_picker'
## MODEL ##
# Input placeholder
input_trace = Input(shape=(x_train.shape[1], x_train.shape[2]))  
x = Conv1D(filters = filters[0], kernel_size = kernel_size, activation=hidden_act_fun, padding = padding)(input_trace)
x = MaxPooling1D(pool_size = pool_size, padding = padding)(x)
x = Conv1D(filters = filters[1], kernel_size = kernel_size, activation=hidden_act_fun, padding = padding)(x)
x = MaxPooling1D(pool_size = pool_size, padding = padding)(x)
cnn_feat = Flatten()(x)
x = Dense(units= 32, activation=hidden_act_fun)(cnn_feat)
x = BatchNormalization()(x)
x = Dense(units = 8, activation=hidden_act_fun)(x)
x = BatchNormalization()(x)
dense = Dense(units= 1, activation=final_act_fun)(x)
# Compile Model
p_phase_picker = Model(input_trace, dense, name = name)
p_phase_picker.compile(optimizer = optimizer, loss = loss_type)
p_phase_picker.summary()
</code></pre>
<pre><code>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 1800, 3)           0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 1800, 32)          608       
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 900, 32)           0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 900, 64)           12352     
_________________________________________________________________
max_pooling1d_2 (MaxPooling1 (None, 450, 64)           0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 28800)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 32)                921632    
_________________________________________________________________
batch_normalization_1 (Batch (None, 32)                128       
_________________________________________________________________
dense_2 (Dense)              (None, 8)                 264       
_________________________________________________________________
batch_normalization_2 (Batch (None, 8)                 32        
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 9         
=================================================================
Total params: 935,025
Trainable params: 934,945
Non-trainable params: 80
_________________________________________________________________
</code></pre>
<hr />
<h2><a name='train_model'>Training the Model</a></h2>
<p>With our data read in and our model architecture defined, we are now ready to run our baseline convolutional neural network. With Keras, this amounts to giving our compiled model the training data set and its associated labels, the number of epochs and batch size we want, and the validation (see below). To train our CNN we use the model&rsquo;s .fit() method:</p>
<pre><code class="language-python"># Train Model
history = p_phase_picker.fit(x = x_train,
                            y = y_train,
                            epochs= epochs,
                            batch_size=batch_size,
                            validation_data=(x_val, y_val))
# Keep track of the last loss values (for easy comparison later)
train_loss = history.history['loss']
last_train_loss_value = train_loss[len(train_loss)-1]
val_loss = history.history['val_loss']
last_val_loss_value = val_loss[len(val_loss) - 1]
</code></pre>
<pre><code class="language-python">Epoch 1/400
5725/5725 [==============================] - 4s 780us/step - loss: 367974.3419 - val_loss: 370470.2668
Epoch 2/400
5725/5725 [==============================] - 4s 632us/step - loss: 367804.4836 - val_loss: 371916.8610
Epoch 3/400
5725/5725 [==============================] - 4s 624us/step - loss: 367594.1336 - val_loss: 370046.7134
Epoch 4/400
5725/5725 [==============================] - 4s 635us/step - loss: 367357.8737 - val_loss: 370197.6924
Epoch 5/400
5725/5725 [==============================] - 4s 647us/step - loss: 367116.8329 - val_loss: 372166.2775
Epoch 6/400
5725/5725 [==============================] - 4s 645us/step - loss: 366859.2670 - val_loss: 371878.3604
Epoch 7/400
5725/5725 [==============================] - 4s 651us/step - loss: 366575.9700 - val_loss: 368855.4593
Epoch 8/400
5725/5725 [==============================] - 4s 644us/step - loss: 366252.4366 - val_loss: 365949.0822
Epoch 9/400
5725/5725 [==============================] - 4s 643us/step - loss: 365918.8507 - val_loss: 353128.8180
Epoch 10/400
5725/5725 [==============================] - 4s 640us/step - loss: 365568.8157 - val_loss: 360134.3884
Epoch 11/400
5725/5725 [==============================] - 4s 643us/step - loss: 365160.4010 - val_loss: 362235.5229
Epoch 12/400
5725/5725 [==============================] - 4s 641us/step - loss: 364738.2535 - val_loss: 352015.1630
Epoch 13/400
5725/5725 [==============================] - 4s 641us/step - loss: 364275.2614 - val_loss: 354300.4198
Epoch 14/400
5725/5725 [==============================] - 4s 634us/step - loss: 363814.7165 - val_loss: 347660.5830
Epoch 15/400
5725/5725 [==============================] - 4s 636us/step - loss: 363339.9869 - val_loss: 357162.0319
Epoch 16/400
5725/5725 [==============================] - 4s 640us/step - loss: 362818.9280 - val_loss: 359878.0607
Epoch 17/400
5725/5725 [==============================] - 4s 637us/step - loss: 362306.8130 - val_loss: 348699.6071
Epoch 18/400
5725/5725 [==============================] - 4s 640us/step - loss: 361731.6002 - val_loss: 349205.2539
Epoch 19/400
5725/5725 [==============================] - 4s 636us/step - loss: 361150.4833 - val_loss: 351060.9939
Epoch 20/400
5725/5725 [==============================] - 4s 635us/step - loss: 360559.7594 - val_loss: 340123.2790
.
.
.
Epoch 385/400
5725/5725 [==============================] - 4s 637us/step - loss: 6572.9224 - val_loss: 18183.6428
Epoch 386/400
5725/5725 [==============================] - 4s 635us/step - loss: 6540.7187 - val_loss: 18267.0756
Epoch 387/400
5725/5725 [==============================] - 4s 635us/step - loss: 6536.7624 - val_loss: 18081.5158
Epoch 388/400
5725/5725 [==============================] - 4s 634us/step - loss: 6536.4518 - val_loss: 18305.2634
Epoch 389/400
5725/5725 [==============================] - 4s 637us/step - loss: 6549.2467 - val_loss: 18346.6905
Epoch 390/400
5725/5725 [==============================] - 4s 639us/step - loss: 6537.4118 - val_loss: 18083.2445
Epoch 391/400
5725/5725 [==============================] - 4s 635us/step - loss: 6526.0619 - val_loss: 18387.9119
Epoch 392/400
5725/5725 [==============================] - 4s 639us/step - loss: 6508.7915 - val_loss: 18279.9480
Epoch 393/400
5725/5725 [==============================] - 4s 633us/step - loss: 6522.6132 - val_loss: 18310.2310
Epoch 394/400
5725/5725 [==============================] - 4s 635us/step - loss: 6518.6792 - val_loss: 18221.4595
Epoch 395/400
5725/5725 [==============================] - 4s 636us/step - loss: 6532.9096 - val_loss: 18169.3012
Epoch 396/400
5725/5725 [==============================] - 4s 638us/step - loss: 6525.6210 - val_loss: 18193.7779
Epoch 397/400
5725/5725 [==============================] - 4s 636us/step - loss: 6519.6705 - val_loss: 18258.7685
Epoch 398/400
5725/5725 [==============================] - 4s 632us/step - loss: 6517.0802 - val_loss: 18250.5715
Epoch 399/400
5725/5725 [==============================] - 4s 633us/step - loss: 6516.5765 - val_loss: 18335.3135
Epoch 400/400
</code></pre>
<hr />
<h2><a name ='interpreting_results'>Interpreting the Results</a></h2>  
<p>What does the above tell us? For each epoch the Keras API prints:</p>
<p>1) Computation time<br />
2) The loss from the training and validation data sets.</p>
<p>The second point is worth discussing. Remember that the overall objective is to create an algorithm that learns from the data we give it. i.e. we want our algorithm to generalize to data it has never seen before. We should expect, therefore, that the training loss decreases for every epoch. Does this happen in our case? Let’s plot the training and validation loss curves (sometimes called ‘learning curves’) to help us understand a little more of how well our deep neural network performed:</p>
<pre><code class="language-python"># Validation loss curves #
fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (10,6))
axes.plot(history.history['loss'])
axes.plot(history.history['val_loss'])
axes.set_title('Model Loss')
axes.set_ylabel('loss')
axes.set_xlabel('epoch')
axes.legend(['Train', 'Validation'], loc='upper left')
</code></pre>
<p><img style="float:left" src="./img/model_loss.png"  >
<b>Figure:</b>  The learning curve results from training the 1D convolutional neural network with the above-mentioned hyperparameters. The red curve depicts loss from the training set, the blue curve depicts loss from the validation set.</p>
<p>The red and blue curves show the loss (sometimes called ‘cost’) per epoch on the training and validation set, respectively. As expected, the neural network performs poorly at the onset of training (at this point the model is probably randomly guessing where the first phase is) and gradually improves with epoch. During training the neural network is learning directly from the training set, so the prediction error (loss/cost) is lower than that of the validation training set.</p>
<p>We stopped training around epoch <span style="font-family:Courier; font-size:1.0em;">400</span> because at this point it would seem our neural network is no longer learning/improving its ability to make predictions. Also, we don’t want to let the neural network run too long, else the neural network might begin to overfit.</p>
<hr />
<h2><a name ='visualize_results'>Visualize the Results</a></h2>  
<p>I don’t know about you, but most of the tutorials I come across normally end here. Meaning, they show a loss curve from training and call it a day. I am a visual person, so I want to see the output of my model. Sure, these learning curves tell me that, to a first-order that my neural network is learning to pick the first arrival. But, how does this look compared to the pick made by a human being? Let’s look at some earthquakes.</p>
<p>Below are two randomly (using Numpy&rsquo;s <span style="font-family:Courier; font-size:1.0em;">rand.randint()</span> function) chosen waveforms from our validation set.  The red vertical line is the pick made by a human. The purple line is the pick made by our CNN.</p>
<pre><code class="language-python">def read_results(file_name):
    file_npz = np.load(file_name)
    read_list = []
    for item in file_npz:
        read_list.append(file_npz[item])
    return np.array(read_list)
</code></pre>
<pre><code class="language-python">directory = './data_directory'
## Read in earthquake waveforms
file = &quot;waves4picking.npz&quot;
file_path = os.path.join(directory, file)
waves_array = read_results(file_path)
# Reshape from (1, 1431, 1800, 3) to (1431, 1800, 3)
waves_array = np.reshape(waves_array, newshape=(waves_array.shape[1], waves_array.shape[2], waves_array.shape[3]))
## Read picks made by people
file2 = &quot;spicks_used.npz&quot;
file_path2 = os.path.join(directory, file2)
ppick_array = read_results(file_path2)
ppick_array = np.reshape(ppick_array, newshape=(ppick_array.shape[1])) # Reshape from (1, 1431) to (1431,)
## Picks made by machine learning
file3 = 'ml_spicks.npz'
file_path3 = os.path.join(directory, file3)
ml_ppicks = read_results(file_path3)
ml_ppicks = np.reshape(ml_ppicks, newshape=(ml_ppicks.shape[1]))    # Reshape from (1, 1431) to (1431,)
</code></pre>
<pre><code class="language-python"># Waveform specs.
sampling_rate = 20.0
npts = 1800 
delta = 0.05
time = np.arange( 0, npts / sampling_rate, delta)
</code></pre>
<pre><code class="language-python"># Let's select waveforms, and their associated picks, randomly
tr = np.random.randint(0, waves_array.shape[0])
tr1 = np.random.randint(0, waves_array.shape[0])
rows = 2
fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(16,8))
axes[0].set_title(&quot;Trace {}&quot;.format(tr))
axes[0].plot(time, waves_array[tr, :, 0], color = 'black')
axes[0].axvline(ppick_array[tr] / sampling_rate, color = 'red', label = &quot;p_pick manual&quot;)
axes[0].axvline(ml_ppicks[tr] / sampling_rate, color = 'purple' , label = 'ml_pick')
axes[1].set_title(&quot;Trace {}&quot;.format(tr1))
axes[1].plot(time, waves_array[tr1, :, 0], color = 'black')
axes[1].axvline(ppick_array[tr1] / sampling_rate, color = 'red', label = &quot;p_pick manual&quot;)
axes[1].axvline(ml_ppicks[tr1] / sampling_rate, color = 'purple' , label = 'ml_pick')
axes[1].set_xlabel(&quot;Time [s]&quot;)
for i in range(rows):
    axes[i].set_ylabel('Norm. Amp.')
    axes[i].legend()
plt.tight_layout()
</code></pre>
<p><img src = "./img/output_27_0.png">
<b>Figure:</b> Two randomly chosen earthquake seismic records from the training set. The red vertical line is the manually selected phase arrival. The purple line depicts the phase pick made by the machine learning algorithm.</p>
<p><br>
You’ll notice that, depending on the waveform, our CNN has varying levels of success in picking the first arrival. This makes sense given that so far we have only run a baseline model; there is still plenty of refining and polishing that has to be done before we can expect too much from our neural network.</p>
<p>What&rsquo;s left do? We&rsquo;ll explore this in the next section.</p>
<hr />
<h2><a name ='whats_next'>What's Next?</a></h2>
<p>There is a lot to do before we can call this model satisfactory. For a start, we should try to get more data. The model results are shown above only used ~10,000 waveforms, which is a bit on the small side for a deep neural network. It might be instructive to try to double or triple the data set and see if our loss curves improve.</p>
<p>We could also play with the complexity of our model. At the moment we only have two, 1D convolutional layers. Perhaps the model will perform better with more or larger filter sizes? (<b>Warning:</b> it is best practice to start small before jumping into larger models!)</p>
<p>One could and should explore the batch sizes and/or using a different optimization method.</p>
<p>We could and should also shift the window where our seismic waveform is centered. Not only might this make our neural network more robust, but it will also increase how much training data we have (i.e. data augmentation).</p>
<p>Once we have reached a point where we are satisfied with how our model is performing we will need to run this on a <b>test set</b>. In other words, we need to run this on a data set which the convolutional neural network has never seen before. We could easily achieve this by setting aside test data when we originally split our data set into a train and validation set.</p>
<p>With pre-trained weights and a model architecture, you can load a test data set and make predictions. The performance of the model on the test set will guide our decision on whether or not we can use this on out-of-sample data. In our case, we want to know if can we use this model to predict the P-wave for new seismic traces.</p>
<h2 id="keras-makes-leading-in-models-and-making-predictions-easy-to-do-and-i-ll-go-into-detail-in-a-future-post-of-how-to-do-this">Keras makes leading in models and making predictions easy to do and I’ll go into detail in a future post of how to do this.</h2>
<h2><a name ='conclusion'>Conclusion</a></h2>
<p>In this tutorial we covered how to <b>compile</b>, <b>train</b>, and make a surface-level <b>evaluation</b> of a baseline convolutional neural network.  In the <a href="https://ngrayluna.github.io/post/p-phase-picker-tutorial_pi/" target="_blank">first part</a> of the tutorial we learned how to frame our problem, download data, process it, and save it into a file format from which we can use later for training our convolutional neural network.</p>
<p>Identifying the first arriving seismic wave generated by an earthquake is a critical component of earthquake early warning and it is a topic of continued interest from both a scientific and public safety point of view. As of writing this post, earthquake early warning recently received funding to support operations, improve existing seismic stations, and expand the current earthquake early warning system across the West Coast.</p>
<p>While there exist non-machine learning earthquake detection systems, it remains to be seen if deep neural networks will play a role in EEW. Deep learning algorithms not only need to classify and detect earthquakes, but they need to do so accurately and faster than current non-Deep Learning algorithms.</p>
<p>You can find the source code to this tutorial on my <a href ="https://github.com/ngrayluna/P_Phase_Picker">GitHub</a>.</p>
<hr />
<hr />
<h3>Suggested Reading Material</h3>  
<ul>
<li><p>Géron, A. (2017). Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques for Building Intelligent Systems. O&rsquo;Reilly UK Ltd.</p></li>
<li><p>Stanford CS class CS231n: <a href="http://cs231n.github.io/" target="_blank">Convolutional Neural Networks for Visual Recognition</a>.</p></li>
<li><p>Ackermann, Nils. &ldquo;Introduction to 1D Convolutional Neural Networks in Keras for Time Sequences&rdquo; <i>Medium</i>, 04 September 2018, <a href="https://blog.goodaudience.com/introduction-to-1d-convolutional-neural-networks-in-keras-for-time-sequences-3a7ff801a2cf" target="_blank">https://blog.goodaudience.com/introduction-to-1d-convolutional-neural-networks-in-keras-for-time-sequences-3a7ff801a2cf</a></p></li>
</ul>
<hr />
<hr />
    </div>
  <div class="media author-card">
      <img class="portrait mr-3" src="/authors/admin/avatar_hu83bf9698254eb6e8b51d368e10a1a98c_35115_250x250_fill_q90_lanczos_center.jpg" alt="Avatar">
    <div class="media-body">
      <h5 class="card-title"><a href="https://ngrayluna.github.io/">Noah Luna</a></h5>
      <h6 class="card-subtitle">Recent MS Graduate Student</h6>
      <p class="card-text">My research interests include applications of deep neural networks in seismology, theoretrical frameworks of deep neural networks, seismic sources, and time-series analysis.</p>
      <ul class="network-icon" aria-hidden="true">
          <li>
            <a href="mailto:nluna@berkeley.edu" >
              <i class="fas fa-envelope"></i>
            </a>
          </li>
          <li>
            <a href="https://github.com/ngrayluna" target="_blank" rel="noopener">
              <i class="fab fa-github"></i>
            </a>
          </li>
          <li>
            <a href="https://www.linkedin.com/in/noah-luna-linked/" target="_blank" rel="noopener">
              <i class="fab fa-linkedin"></i>
            </a>
          </li>
          <li>
            <a href="/files/cv_gen.pdf" >
              <i class="ai ai-cv"></i>
            </a>
          </li>
      </ul>
    </div>
  </div>
  </div>
</article>
    <script src="/js/mathjax-config.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.0.0/mermaid.min.js" integrity="sha256-0w92bcB21IY5+rGI84MGj52jNfHNbXVeQLrZ0CGdjNY=" crossorigin="anonymous" title="mermaid"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js" integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/r.min.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.js" integrity="sha512-lInM/apFSqyy1o6s89K4iQUKg6ppXEgsVxT35HbzUupEVRh2Eu9Wdl4tHj7dZO0s1uvplcYGmt3498TtHq+log==" crossorigin="anonymous"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    <script src="/js/academic.min.130521ecfc6f534c52c158217bbff718.js"></script>
  <div class="container">
    <footer class="site-footer">
    <p class="powered-by">
    Copyright © 2019 Gray Luna
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
  </p>
</footer>
  </div>
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>
</body>
</html>
    <footer class="post-footer">
        <div class="post-tags">
            <a href="/tags/Bokeh/" rel="tag"># Bokeh</a>
            <a href="/tags/Kafka/" rel="tag"># Kafka</a>
            <a href="/tags/Cassandra/" rel="tag"># Cassandra</a>
        </div>
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
              <a href="/posts/63adf3bb/" rel="next" title="Data Analysis of K-POP: Playing with Spotify API">
                <i class="fa fa-chevron-left"></i> Data Analysis of K-POP: Playing with Spotify API
              </a>
          </div>
          <span class="post-nav-divider"></span>
          <div class="post-nav-prev post-nav-item">
              <a href="/posts/9b3e7e9e/" rel="prev" title="CS229 Note: Linear Regression, Logistic regression, Generalized Linear Models">
                CS229 Note: Linear Regression, Logistic regression, Generalized Linear Models <i class="fa fa-chevron-right"></i>
              </a>
          </div>
        </div>
    </footer>
  </div>
  </article>
  </div>
          </div>
    <div class="comments" id="comments">
        <div id="gitment-container"></div>
    </div>
        </div>
<div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>
  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
              <p class="site-author-name" itemprop="name">Kamel Chehboun</p>
              <div class="site-description motion-element" itemprop="description"></div>
          </div>
            <nav class="site-state motion-element">
                <div class="site-state-item site-state-posts">
                  <a href="/archives">
                    <span class="site-state-item-count">44</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
                <div class="site-state-item site-state-categories">
                                        <a href="/categories/">
                    <span class="site-state-item-count">8</span>
                    <span class="site-state-item-name">categories</span>
                  </a>
                </div>
                <div class="site-state-item site-state-tags">
                      <a href="/tags/">
                    <span class="site-state-item-count">34</span>
                    <span class="site-state-item-name">tags</span>
                  </a>
                </div>
            </nav>
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
            <div class="links-of-author motion-element">
                <span class="links-of-author-item">
                  <a href="https://github.com/kdsmel" title="GitHub &rarr; https://github.com/kdsmel" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i></a>
                </span>
            </div>
        </div>
      </div>
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#architecture"><span class="nav-number">2.</span> <span class="nav-text">Architecture</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#stock-streaming-fundamental"><span class="nav-number">2.1.</span> <span class="nav-text">1 Stock: Streaming &amp; Fundamental</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#data-source"><span class="nav-number">2.1.1.</span> <span class="nav-text">1.1 Data Source</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#etl"><span class="nav-number">2.1.2.</span> <span class="nav-text">1.2 ETL</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#historical-data"><span class="nav-number">2.1.2.1.</span> <span class="nav-text">1. Historical data</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#realtime-data"><span class="nav-number">2.1.2.2.</span> <span class="nav-text">2. Realtime data</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#fundatmental-data"><span class="nav-number">2.1.2.3.</span> <span class="nav-text">3. Fundatmental data</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#stock-comparison"><span class="nav-number">2.2.</span> <span class="nav-text">2 Stock: Comparison</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#economy"><span class="nav-number">2.3.</span> <span class="nav-text">3 Economy</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#data-source-1"><span class="nav-number">2.3.1.</span> <span class="nav-text">3.1 Data Source</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#etl-1"><span class="nav-number">2.3.2.</span> <span class="nav-text">3.2 ETL</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#economy-data"><span class="nav-number">2.3.2.1.</span> <span class="nav-text">1. Economy data</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#business-news"><span class="nav-number">2.3.2.2.</span> <span class="nav-text">2. Business news</span></a></li></ol></li></ol></li></ol></li></ol></div>
          </div>
        </div>
      <!--/noindex-->
    </div>
  </aside>
      </div>
    </main>
    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Kamel Chehboun</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="Symbols count total">518k</span>
</div>
      </div>
    </footer>
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
      </div>
  </div>
<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>
  <script color="0,0,255" opacity="0.5" zindex="-1" count="99" src="//cdn.bootcss.com/canvas-nest.js/1.0.1/canvas-nest.min.js"></script>
  <script id="ribbon" size="300" alpha="0.6" zindex="-1" src="/lib/canvas-ribbon/canvas-ribbon.js"></script>
  <script src="//cdn.jsdelivr.net/jquery/2.1.3/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/fastclick/1.0.6/fastclick.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery-lazyload@1/jquery.lazyload.min.js"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  <script src="/lib/fancybox/source/jquery.fancybox.pack.js"></script>
  <script src="/lib/three/three.min.js"></script>
  <script src="/lib/three/three-waves.min.js"></script>
  <script src="/lib/three/canvas_lines.min.js"></script>
  <script src="/lib/three/canvas_sphere.min.js"></script>
  <script src="/js/utils.js?v=7.1.2"></script>
  <script src="/js/motion.js?v=7.1.2"></script>
  <script src="/js/schemes/muse.js?v=7.1.2"></script>
  <script src="/js/scrollspy.js?v=7.1.2"></script>
<script src="/js/post-details.js?v=7.1.2"></script>
  <script src="/js/next-boot.js?v=7.1.2"></script>
<script>
  function renderGitment() {
    var gitment = new Gitment({
      id: window.location.pathname,
      owner: 'kdsmel',
      repo: 'kdsmel.github.io',
      oauth: {
        client_secret: '75adc257166813deff478053f3f05133285d6cf0',
        client_id: '90ddd3d00d8930cb0d84'
      }
    });
    gitment.render('gitment-container');
  }
    renderGitment();
</script>
 <script type="text/x-mathjax-config">
   MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });
  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') { next = next.nextSibling }
        if (next && next.nodeName.toLowerCase() === 'br') { next.parentNode.removeChild(next) }
      }
    });
  });
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      document.getElementById(all[i].inputID + '-Frame').parentNode.className += ' has-jax';
    }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>
<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>
<script type="text/javascript" src="/js/src/dynamic_bg.js"></script>
